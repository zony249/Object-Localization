{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac8abbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-14 22:33:35.212311: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorboard\n",
    "import torch\n",
    "import torchmetrics\n",
    "\n",
    "from pvloader import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe7f905",
   "metadata": {},
   "source": [
    "## Indexing our Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfd9db59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "number of data examples: 17125\n",
      "number of classes: 20\n"
     ]
    }
   ],
   "source": [
    "VOCPATH = \"../VOCdevkit/VOC2012\"\n",
    "LABELS_PATH = os.path.join(VOCPATH, \"label_preproc/\")\n",
    "IMG_PATH = os.path.join(VOCPATH, \"jpeg_preproc/\")\n",
    "\n",
    "\n",
    "\n",
    "data_index = Data_index(IMG_PATH, LABELS_PATH, k=10)\n",
    "\n",
    "\n",
    "print(f\"\\n\\nnumber of data examples: {data_index.size()}\")\n",
    "print(f\"number of classes: {data_index.num_classes()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90120ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d62dec",
   "metadata": {},
   "source": [
    "## Defining our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2bedd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "from torch.cuda.amp import autocast, GradScaler\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\" \n",
    "\n",
    "\n",
    "device = torch.device(dev) \n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b64b8cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module, Conv2d, BatchNorm2d, ReLU, MaxPool2d, Dropout2d\n",
    "from torch.nn.init import xavier_normal_, kaiming_normal_\n",
    "\n",
    "\n",
    "\n",
    "class Bottleneck_Conv(Module):\n",
    "    def __init__(self, in_channels, \n",
    "                 out_channels, \n",
    "                 kernel_size, \n",
    "                 stride=1, \n",
    "                 padding=0, \n",
    "                 drop=0):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        self.squeeze = Conv2d(in_channels, in_channels//4, kernel_size=(1,1), stride=1, padding=0, bias=False)\n",
    "        self.bn1 = BatchNorm2d(in_channels//4)\n",
    "        self.a1 = ReLU()\n",
    "        self.d1 = Dropout2d(drop)\n",
    "        \n",
    "        self.conv = Conv2d(in_channels//4, in_channels//4, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n",
    "        self.bn2 = BatchNorm2d(in_channels//4)\n",
    "        self.a2 = ReLU()\n",
    "        self.d2 = Dropout2d(drop)\n",
    "        \n",
    "        \n",
    "        self.expand = Conv2d(in_channels//4, out_channels, kernel_size=(1,1), stride=1, padding=0, bias=False)\n",
    "        self.bn3 = BatchNorm2d(out_channels)\n",
    "        self.a3 = ReLU()\n",
    "        self.d3 = Dropout2d(drop)\n",
    "        \n",
    "        \n",
    "        self.bypass = Conv2d(in_channels, out_channels, kernel_size=(1,1), stride=stride, padding=0, bias=False)\n",
    "        self.bnb = BatchNorm2d(out_channels)\n",
    "        self.ab = ReLU()\n",
    "        self.db = Dropout2d(drop)\n",
    "        \n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_bypass = x\n",
    "        \n",
    "        x = self.squeeze(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.a1(x)\n",
    "        x = self.d1(x)\n",
    "        \n",
    "        x = self.conv(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.a2(x)\n",
    "        x = self.d2(x)\n",
    "        \n",
    "        x = self.expand(x)\n",
    "        \n",
    "        x_bypass = self.bypass(x_bypass)\n",
    "        x_bypass = self.bnb(x_bypass)\n",
    "        x_bypass = self.ab(x_bypass)\n",
    "        x_bypass = self.db(x_bypass)\n",
    "        \n",
    "        x = self.bn3(x + x_bypass)\n",
    "        x = self.a3(x)\n",
    "        x = self.d3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def init_weights(self):\n",
    "        kaiming_normal_(self.squeeze.weight)\n",
    "        kaiming_normal_(self.conv.weight)\n",
    "        kaiming_normal_(self.expand.weight)\n",
    "        kaiming_normal_(self.bypass.weight)\n",
    "    \n",
    "    \n",
    "class Bottleneck_Id(Module):\n",
    "    def __init__(self, in_channels,  \n",
    "                 kernel_size, \n",
    "                 padding=0,\n",
    "                 drop=0):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        self.squeeze = Conv2d(in_channels, in_channels//4, kernel_size=(1,1), stride=1, padding=0, bias=False)\n",
    "        self.bn1 = BatchNorm2d(in_channels//4)\n",
    "        self.a1 = ReLU()\n",
    "        self.d1 = Dropout2d(drop)\n",
    "        \n",
    "        self.conv = Conv2d(in_channels//4, in_channels//4, kernel_size=kernel_size, stride=1, padding=padding, bias=False)\n",
    "        self.bn2 = BatchNorm2d(in_channels//4)\n",
    "        self.a2 = ReLU()\n",
    "        self.d2 = Dropout2d(drop)\n",
    "        \n",
    "        self.expand = Conv2d(in_channels//4, in_channels, kernel_size=(1,1), stride=1, padding=0, bias=False)\n",
    "        self.bn3 = BatchNorm2d(in_channels)\n",
    "        self.a3 = ReLU()\n",
    "        self.d3 = Dropout2d(drop)\n",
    "        \n",
    "\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_bypass = x\n",
    "        \n",
    "        x = self.squeeze(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.a1(x)\n",
    "        x = self.d1(x)\n",
    "        \n",
    "        x = self.conv(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.a2(x)\n",
    "        x = self.d2(x)\n",
    "        \n",
    "        x = self.expand(x)\n",
    "        x = self.bn3(x + x_bypass)\n",
    "        x = self.a3(x)\n",
    "        x = self.d3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def init_weights(self):\n",
    "        kaiming_normal_(self.squeeze.weight)\n",
    "        kaiming_normal_(self.conv.weight)\n",
    "        kaiming_normal_(self.expand.weight)\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "95600d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import MaxPool2d, ReLU, BatchNorm2d, Sigmoid, Softmax2d, Dropout\n",
    "from torch.optim import Adam\n",
    "from tensorflow.keras.utils import Progbar\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "class DeepMarker(Module):\n",
    "\n",
    "  \n",
    "    def __init__(self, rows, cols, channels=3, num_of_classes=20, drop=0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "\n",
    "        \n",
    "        #x = torch.rand((1, 3, 416, 416))\n",
    "        \n",
    "        self.backbone = models.resnet18(pretrained=True)\n",
    "        self.backbone = torch.nn.Sequential(*list(self.backbone.children())[:-3])\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "        # print(self.backbone)\n",
    "        #print(self.backbone(x).shape)\n",
    "        \n",
    "        \n",
    "        # Input: (26, 26, 256)\n",
    "        self.conv1 = Bottleneck_Conv(256, 384, kernel_size=3, stride=1, padding=1, drop=drop)\n",
    "        self.id1_1 = Bottleneck_Id(384, kernel_size=3, padding=1, drop=drop)\n",
    "        self.id1_2 = Bottleneck_Id(384, kernel_size=3, padding=1, drop=drop)\n",
    "        self.id1_3 = Bottleneck_Id(384, kernel_size=3, padding=1, drop=drop)\n",
    "        \n",
    "        # Input: (26, 26, 384)\n",
    "        self.conv2 = Bottleneck_Conv(384, 512, kernel_size=3, stride=2, padding=1, drop=drop)\n",
    "        self.id2_1 = Bottleneck_Id(512, kernel_size=3, padding=1, drop=drop)\n",
    "        self.id2_2 = Bottleneck_Id(512, kernel_size=3, padding=1, drop=drop)\n",
    "        self.id2_3 = Bottleneck_Id(512, kernel_size=3, padding=1, drop=drop)\n",
    "        self.id2_4 = Bottleneck_Id(512, kernel_size=3, padding=1, drop=drop)\n",
    "        self.id2_5 = Bottleneck_Id(512, kernel_size=3, padding=1, drop=drop)\n",
    "    \n",
    "        # Input: (13, 13, 512)\n",
    "        self.conv_conf = Conv2d(in_channels=512, out_channels=1, kernel_size=(1, 1), stride=1, padding=0, bias=True)\n",
    "        self.bn_conf = BatchNorm2d(1)\n",
    "        self.a_conf = Sigmoid()\n",
    "        \n",
    "        self.conv_bbox = Conv2d(in_channels=512, out_channels=4, kernel_size=(1, 1), stride=1, padding=0, bias=False)\n",
    "        self.bn_bbox = BatchNorm2d(num_features=4)\n",
    "        \n",
    "        self.conv_class = Conv2d(in_channels=512, out_channels=num_of_classes, kernel_size=(1, 1), stride=1, padding=0, bias=False)\n",
    "        self.bn_class = BatchNorm2d(num_features=num_of_classes)\n",
    "        self.a_class = Softmax2d()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        x = x.to(memory_format=torch.channels_last)\n",
    "        \n",
    "        x = self.backbone(x)\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.id1_1(x)\n",
    "        x = self.id1_2(x)\n",
    "        x = self.id1_3(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.id2_1(x)\n",
    "        x = self.id2_2(x)\n",
    "        x = self.id2_3(x)\n",
    "        x = self.id2_4(x)\n",
    "        x = self.id2_5(x)\n",
    "        \n",
    "        x_conf = self.conv_conf(x)\n",
    "        x_conf = self.bn_conf(x)\n",
    "        x_conf = self.a_conf(x_conf)\n",
    "        \n",
    "        x_bbox = self.conv_bbox(x)\n",
    "        x_bbox = self.bn_bbox(x_bbox)\n",
    "        \n",
    "        x_class = self.conv_class(x)\n",
    "        x_class = self.bn_class(x_class)\n",
    "        x_class = self.a_class(x_class)\n",
    "        \n",
    "        x_out = torch.cat((x_conf, x_bbox, x_class), dim=1)\n",
    "        \n",
    "        return x_out\n",
    "    \n",
    "    def init_weights(self):\n",
    "        pass\n",
    "        \n",
    "        \n",
    "    def train_step(self, x, y, scaler=None):\n",
    "        with autocast():\n",
    "            y_pred = self(x)\n",
    "            loss = self.loss_fn(y, y_pred)\n",
    "        if scaler is not None:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(self.opt)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            self.opt.step()\n",
    "        return loss, y_pred\n",
    "        \n",
    "                \n",
    "        \n",
    "    def fit(self, d_idx, loss_fn, opt, epochs=1, batch_size=32, metrics=[]):\n",
    "\n",
    "        scaler = GradScaler()\n",
    "        self.loss_fn = loss_fn\n",
    "        self.opt = opt\n",
    "        \n",
    "        t_size = len(d_idx.trainset)\n",
    "        t_steps = t_size // batch_size\n",
    "        \n",
    "        v_size = len(d_idx.valset)\n",
    "        v_steps = v_size // batch_size\n",
    "\n",
    "        for i in range(epochs):\n",
    "            \n",
    "            t_gen, v_gen = d_idx.get_generators(batch_size)\n",
    "            \n",
    "            \n",
    "            \n",
    "            print(f\"Epoch {i+1}/{epochs}\")\n",
    "            mets = [\"loss\"]\n",
    "            mets.append(x.__name__ for x in metrics)\n",
    "            mets.append(\"val_loss\")\n",
    "            mets.append(\"val_\" + x.__name__ for x in metrics)\n",
    "            progbar = Progbar(t_steps, stateful_metrics=[\"loss\"])\n",
    "\n",
    "            for j in range(t_steps):\n",
    "                self.train()\n",
    "                opt.zero_grad()\n",
    "                X_train, Y_train = next(t_gen)\n",
    "                X_train = X_train.to(device)\n",
    "                Y_train = Y_train.permute(0, 3, 1, 2).to(device)\n",
    "\n",
    "                loss, Y_pred = self.train_step(X_train, Y_train, scaler)\n",
    "                \n",
    "                \n",
    "                mtx = [(\"loss\",loss.item())]\n",
    "                for x in metrics:\n",
    "                    mtx.append((x.__name__, x(Y_train, Y_pred).item()))\n",
    "                progbar.update(j+1, values=mtx)\n",
    "                \n",
    "                \n",
    "            if v_gen is not None:\n",
    "                loss_v = 0\n",
    "                v_batch_size = None\n",
    "                \n",
    "                mtx_vals = torch.zeros(len(metrics), device=device)\n",
    "                \n",
    "                for j in range(v_steps):\n",
    "                    with torch.no_grad():\n",
    "                        self.eval()\n",
    "                        X_v, Y_v = next(v_gen)\n",
    "                        if v_batch_size is None:\n",
    "                            v_batch_size = X_v.shape[0]\n",
    "                        X_v = X_v.to(device)\n",
    "                        Y_v = Y_v.permute(0, 3, 1, 2).to(device)\n",
    "                        Y_pred_v = self(X_v)\n",
    "                        loss_v += self.loss_fn(Y_v, Y_pred_v).item()\n",
    "                        \n",
    "                        for i, x in enumerate(metrics):\n",
    "                            mtx_vals[i] += x(Y_v, Y_pred_v).item()\n",
    "                        \n",
    "                loss_v /= v_steps\n",
    "                mtx.append((\"val_loss\", loss_v))\n",
    "                \n",
    "                mtx_vals /= v_steps\n",
    "                for i, x in enumerate(metrics):\n",
    "                    mtx.append((\"val_\" + x.__name__, mtx_vals[i].item()))\n",
    "                \n",
    "                #print(mtx)\n",
    "                progbar.update(t_steps, values=mtx)\n",
    "                    \n",
    "            print(\"\")\n",
    "            \n",
    "            torch.save({ \"model_state_dict\": self.state_dict(),\n",
    "                         \"optim_state_dict\": opt.state_dict()}, \n",
    "                         \"model.pt\")\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "437201ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, y_true, y_pred):\n",
    "        \n",
    "        m = y_true.shape[0]\n",
    "        c = y_true.shape[1]\n",
    "        h = y_true.shape[2]\n",
    "        w = y_true.shape[3]\n",
    "        \n",
    "        conf_true = y_true[:, 0:1, :, :]\n",
    "        conf_pred = y_pred[:, 0:1, :, :]\n",
    "        conf_loss = torch.sum(-conf_true*torch.log(conf_pred + 1e-3) - (1-conf_true)*torch.log(1-conf_pred + 1e-3))/m\n",
    "        \n",
    "        bbox_true = y_true[:, 1:5, :, :]\n",
    "        bbox_pred = y_pred[:, 1:5, :, :]\n",
    "        #print(bbox_true.shape, bbox_pred.shape, conf_true.shape)\n",
    "        bbox_loss = torch.sum((bbox_true-bbox_pred)**2 * conf_true)/m\n",
    "        \n",
    "        class_true = y_true[:, 5:, :, :]\n",
    "        class_pred = y_pred[:, 5:, :, :] \n",
    "        class_loss = torch.sum(torch.sum(-class_true*torch.log(class_pred+1e-3), dim=1) * conf_true)/m\n",
    "        \n",
    "        loss = conf_loss + 5 * bbox_loss + class_loss\n",
    "        return loss\n",
    "    \n",
    "def confidence(y_true, y_pred):\n",
    "    m = y_true.shape[0]\n",
    "    c = y_true.shape[1]\n",
    "    h = y_true.shape[2]\n",
    "    w = y_true.shape[3]\n",
    "        \n",
    "    conf_true = y_true[:, 0:1, :, :]\n",
    "    conf_pred = y_pred[:, 0:1, :, :]\n",
    "    conf_loss = torch.sum(-conf_true*torch.log(conf_pred + 1e-3) - (1-conf_true)*torch.log(1-conf_pred + 1e-3))/m\n",
    "    \n",
    "    return conf_loss\n",
    "\n",
    "def bbox(y_true, y_pred):\n",
    "    m = y_true.shape[0]\n",
    "    c = y_true.shape[1]\n",
    "    h = y_true.shape[2]\n",
    "    w = y_true.shape[3]\n",
    "        \n",
    "    conf_true = y_true[:, 0:1, :, :]\n",
    "        \n",
    "    bbox_true = y_true[:, 1:5, :, :]\n",
    "    bbox_pred = y_pred[:, 1:5, :, :]\n",
    "    #print(bbox_true.shape, bbox_pred.shape, conf_true.shape)\n",
    "    bbox_loss = torch.sum((bbox_true-bbox_pred)**2 * conf_true)/m\n",
    "    return 5 * bbox_loss\n",
    "    \n",
    "def class_loss(y_true, y_pred):\n",
    "    m = y_true.shape[0]\n",
    "    c = y_true.shape[1]\n",
    "    h = y_true.shape[2]\n",
    "    w = y_true.shape[3]\n",
    "        \n",
    "    conf_true = y_true[:, 0:1, :, :]\n",
    "\n",
    "    class_true = y_true[:, 5:, :, :]\n",
    "    class_pred = y_pred[:, 5:, :, :] \n",
    "    class_loss = torch.sum(torch.sum(-class_true*torch.log(class_pred + 1e-3), dim=1) * conf_true)/m\n",
    "    return class_loss\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8349938a",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## Training the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6284dc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-5\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "N_CLASSES = 20\n",
    "\n",
    "model = DeepMarker(416, 416, 3, num_of_classes=N_CLASSES, drop=0.2).to(device=device, memory_format=torch.channels_last)\n",
    "\n",
    "criterion = CustomLoss()\n",
    "optimizer = Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b01ff288",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'class_to_idx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_435420/3746254891.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconfidence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_435420/2728295944.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, d_idx, loss_fn, opt, epochs, batch_size, metrics)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mt_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_generators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Object-Localization/pvloader.py\u001b[0m in \u001b[0;36mget_generators\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_generators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulate_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mtrain_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mval_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'class_to_idx'"
     ]
    }
   ],
   "source": [
    "model.fit(data_index, criterion, optimizer, epochs=EPOCHS, batch_size=BATCH_SIZE, metrics=[confidence, bbox, class_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572bb7ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
